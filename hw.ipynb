{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "        B  LSTAT  MEDV  \n",
       "0  396.90   4.98  24.0  \n",
       "1  396.90   9.14  21.6  \n",
       "2  392.83   4.03  34.7  \n",
       "3  394.63   2.94  33.4  \n",
       "4  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(load_boston()['filename'], skiprows=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['MEDV'])\n",
    "y = data['MEDV']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6687594935356279"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Дерево решений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_depth = DecisionTreeRegressor().fit(X_train, y_train).get_depth()\n",
    "\n",
    "def get_dtr_score(depth, leaves):\n",
    "    sum_score = 0\n",
    "    n = 10\n",
    "    for i in range(n):\n",
    "        dtr = DecisionTreeRegressor(max_depth=depth, min_samples_leaf=leaves).fit(X_train, y_train)\n",
    "        sum_score += dtr.score(X_test, y_test)\n",
    "        \n",
    "    return sum_score / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for depth in range(default_depth):\n",
    "    a = [get_dtr_score(depth+1, leaves+1) for leaves in range(20)]\n",
    "    score.append(a)\n",
    "    \n",
    "score = np.array(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimum\n",
      "Depth: 7, Min number of samples in leaves: 3, \n",
      "Score: 0.8847578253578587\n",
      "-------------------\n",
      "Linear Regression score: 0.6687594935356279\n"
     ]
    }
   ],
   "source": [
    "res = np.where(score == np.amax(score))\n",
    "coords = list(zip(res[0], res[1]))[0]\n",
    "print('Optimum')\n",
    "print('Depth: {}, Min number of samples in leaves: {}, \\nScore: {}'.format(coords[0] + 1, coords[1] + 1, \n",
    "                                                                         get_dtr_score(coords[0] + 1, coords[1] + 1)))\n",
    "print('-------------------\\nLinear Regression score:', lin_reg.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEPTH\t|LEAVES\n",
      "---------------\n",
      "     \t|[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "1    \t|[0.3602157 0.3602157 0.3602157 0.3602157 0.3602157 0.3602157 0.3602157\n",
      " 0.3602157 0.3602157 0.3602157 0.3602157 0.3602157 0.3602157 0.3602157\n",
      " 0.3602157 0.3602157 0.3602157 0.3602157 0.3602157 0.3602157]\n",
      "2    \t|[0.64554957 0.64554957 0.64554957 0.64554957 0.64554957 0.64554957\n",
      " 0.64554957 0.64554957 0.64554957 0.64554957 0.64554957 0.64554957\n",
      " 0.64554957 0.64554957 0.64554957 0.64554957 0.64554957 0.64554957\n",
      " 0.64554957 0.64554957]\n",
      "3    \t|[0.80709666 0.79501241 0.81461802 0.80547311 0.71759757 0.71616719\n",
      " 0.71506919 0.70595595 0.70595595 0.70595595 0.70595595 0.70595595\n",
      " 0.70589529 0.69995525 0.69995525 0.69995525 0.69995525 0.69995525\n",
      " 0.69995525 0.69995525]\n",
      "4    \t|[0.81733225 0.77011727 0.85156974 0.84225613 0.72074948 0.71942503\n",
      " 0.71629093 0.73178022 0.72881799 0.72817192 0.71698547 0.70856518\n",
      " 0.71051005 0.7084466  0.7084466  0.7084466  0.7084466  0.7084466\n",
      " 0.7084466  0.7084466 ]\n",
      "5    \t|[0.82682252 0.81474201 0.88118701 0.85893775 0.75041619 0.7571543\n",
      " 0.75749815 0.77216883 0.76470766 0.76509216 0.74119868 0.73277839\n",
      " 0.73622868 0.74621974 0.74621974 0.74621974 0.73726516 0.73798956\n",
      " 0.73675143 0.73153236]\n",
      "6    \t|[0.80781025 0.82806592 0.86646789 0.84687661 0.78477335 0.78448825\n",
      " 0.77327447 0.77802579 0.77056462 0.77571767 0.75100389 0.74728745\n",
      " 0.74553574 0.7555268  0.7555268  0.7555268  0.74657222 0.74729663\n",
      " 0.7460585  0.74083942]\n",
      "7    \t|[0.83508714 0.84386883 0.88475783 0.85751059 0.79546741 0.7941118\n",
      " 0.78306734 0.78289275 0.77543157 0.78124746 0.75608466 0.76598347\n",
      " 0.76860586 0.76680757 0.76646973 0.75740428 0.7484497  0.7491741\n",
      " 0.74793597 0.7427169 ]\n",
      "8    \t|[0.8158187  0.82760563 0.87806743 0.84676455 0.79251786 0.79904421\n",
      " 0.78671576 0.78649223 0.77698026 0.78404797 0.75766827 0.76590622\n",
      " 0.7699438  0.76814552 0.76456699 0.75550154 0.74703061 0.74757241\n",
      " 0.74642558 0.74077567]\n",
      "9    \t|[0.85990572 0.82331316 0.87265815 0.83637149 0.79445915 0.79075397\n",
      " 0.78260163 0.78533398 0.77582202 0.78288972 0.75651003 0.76463294\n",
      " 0.7699438  0.76814552 0.76456699 0.75550154 0.74703061 0.74775501\n",
      " 0.74642558 0.74077567]\n",
      "10    \t|[0.81765358 0.76848404 0.86032613 0.83283501 0.79627435 0.79241502\n",
      " 0.78084183 0.7829975  0.77348553 0.78055324 0.75417354 0.76463294\n",
      " 0.7699438  0.76814552 0.76456699 0.75550154 0.74693931 0.74784631\n",
      " 0.74651688 0.74077567]\n",
      "11    \t|[0.83644574 0.78764508 0.86163032 0.83029933 0.79674569 0.79329432\n",
      " 0.77895992 0.78125477 0.77198849 0.77910017 0.75272048 0.76463294\n",
      " 0.7699438  0.76814552 0.76456699 0.75550154 0.74657412 0.74784631\n",
      " 0.74642558 0.74077567]\n",
      "12    \t|[0.79132313 0.7759791  0.86254821 0.83483651 0.79556645 0.79179423\n",
      " 0.77895992 0.78125477 0.77202319 0.77910017 0.75272048 0.76463294\n",
      " 0.7699438  0.76814552 0.76456699 0.75550154 0.74693931 0.74784631\n",
      " 0.74679078 0.74077567]\n",
      "13    \t|[0.78940731 0.80310621 0.86207877 0.83548621 0.79415738 0.7907825\n",
      " 0.77895992 0.78125477 0.77198849 0.77910017 0.75272048 0.76463294\n",
      " 0.7699438  0.76814552 0.76456699 0.75550154 0.74703061 0.74775501\n",
      " 0.74642558 0.74077567]\n",
      "14    \t|[0.82023048 0.84459033 0.86329464 0.83471954 0.79415738 0.7907825\n",
      " 0.77895992 0.78125477 0.77205789 0.77910017 0.75272048 0.76463294\n",
      " 0.7699438  0.76814552 0.76456699 0.75550154 0.74703061 0.74793761\n",
      " 0.74624299 0.74077567]\n",
      "15    \t|[0.79141276 0.80549345 0.86255728 0.8348977  0.79415738 0.7907825\n",
      " 0.77895992 0.78125477 0.77205789 0.77910017 0.75272048 0.76463294\n",
      " 0.7699438  0.76814552 0.76456699 0.75550154 0.74712191 0.74757241\n",
      " 0.74651688 0.74077567]\n",
      "16    \t|[0.76215705 0.79441021 0.86317768 0.83510919 0.79415738 0.7907825\n",
      " 0.77895992 0.78125477 0.77191909 0.77910017 0.75272048 0.76463294\n",
      " 0.7699438  0.76814552 0.76456699 0.75550154 0.74693931 0.74775501\n",
      " 0.74633429 0.74077567]\n",
      "17    \t|[0.82249974 0.79786021 0.86236526 0.83430919 0.79415738 0.7907825\n",
      " 0.77895992 0.78125477 0.77198849 0.77910017 0.75272048 0.76463294\n",
      " 0.7699438  0.76814552 0.76456699 0.75550154 0.74721321 0.74766371\n",
      " 0.74660818 0.74077567]\n",
      "18    \t|[0.82108612 0.80046499 0.86234641 0.83549428 0.79415738 0.7907825\n",
      " 0.77895992 0.78125477 0.77202319 0.77910017 0.75272048 0.76463294\n",
      " 0.7699438  0.76814552 0.76456699 0.75550154 0.74693931 0.74775501\n",
      " 0.74633429 0.74077567]\n",
      "19    \t|[0.77209257 0.77777871 0.86324709 0.83509656 0.79415738 0.7907825\n",
      " 0.77895992 0.78125477 0.77195379 0.77910017 0.75272048 0.76463294\n",
      " 0.7699438  0.76814552 0.76456699 0.75550154 0.74693931 0.74757241\n",
      " 0.74642558 0.74077567]\n"
     ]
    }
   ],
   "source": [
    "print('DEPTH\\t|LEAVES\\n---------------')\n",
    "print('     \\t|{}'.format([_+1 for _ in range(score.shape[1])]))\n",
    "for depth in range(score.shape[0]):\n",
    "    print('{}    \\t|{}'.format(depth+1, score[depth]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
